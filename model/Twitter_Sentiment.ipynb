{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8a73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import nltk\n",
    "import requests\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87489e4",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c2668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(s):\n",
    "    import re\n",
    "    import string\n",
    "    pattern = re.compile('[\\u4e00-\\u9fa5]')\n",
    "    s = re.sub(pattern,\"\",s)\n",
    "    s = re.sub('[^A-Za-z.]',' ',s)\n",
    "    punc = string.punctuation+\"‘’“”—…‑\"\n",
    "    pattern = '[{}]'.format(re.escape(punc))\n",
    "    s = re.sub(pattern, ' ', s)\n",
    "    s = \" \".join(s.split())\n",
    "    s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31560e25",
   "metadata": {},
   "source": [
    "# Remove @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16605d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_at(s):\n",
    "    s = str(s)\n",
    "    s_l = s.split()\n",
    "    ret_s = ''\n",
    "    count = 0\n",
    "    for i in range(len(s_l)):\n",
    "        temp = s_l[i]\n",
    "        if temp[0] == '@' and len(temp) != 1:\n",
    "            count += 1\n",
    "        else:\n",
    "            ret_s += ' '+temp\n",
    "    ret_s = ret_s[1:]\n",
    "    return {'count': count,\n",
    "            'return_string': ret_s}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f742d9",
   "metadata": {},
   "source": [
    "# Turn Hashtag to Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed78cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtag(s):\n",
    "    s = str(s)\n",
    "    s_l = s.split()\n",
    "    count = 0\n",
    "    tag_l = []\n",
    "    ret_s = ''\n",
    "    for i in range(len(s_l)):\n",
    "        temp = s_l[i]\n",
    "        if temp[0] == '#' and len(temp) != 1:\n",
    "            count += 1\n",
    "            tag_l.append(temp[1:])\n",
    "            ret_s += ' ' + temp[1:]\n",
    "        else:\n",
    "            ret_s += ' ' + temp\n",
    "    ret_s = ret_s[1:]\n",
    "    for i in range(len(tag_l)):\n",
    "        tag_l[i] = remove_punc(tag_l[i])\n",
    "    return {'tag_count': count,\n",
    "            'tags': tag_l,\n",
    "            'return_string': ret_s}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddc5e4",
   "metadata": {},
   "source": [
    "# Remove Hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127436c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyperlink(s):\n",
    "    s = str(s)\n",
    "    ret_s = ''\n",
    "    s_l = s.strip('\\n').split()\n",
    "    for i in range(len(s_l)):\n",
    "        temp = s_l[i]\n",
    "        if temp[:4] == 'http':\n",
    "            continue\n",
    "        else:\n",
    "            ret_s += ' ' + temp\n",
    "    ret_s = ret_s[1:]\n",
    "    return ret_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5b1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3152f27",
   "metadata": {},
   "source": [
    "# Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640ba26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376f996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_process(s):\n",
    "    s_demo = emoji.demojize(s)\n",
    "    ret_s = remove_punc(s_demo)\n",
    "    return ret_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d9173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ecda64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6998f1",
   "metadata": {},
   "source": [
    "## Remove Stopping Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a056211f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_stop_word(words):\n",
    "    ret_l = []\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        if w not in STOPWORDS:\n",
    "            ret_l.append(w)\n",
    "    return ret_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b951bd",
   "metadata": {},
   "source": [
    "# Pos & Neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f297a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(url):\n",
    "    word_list = requests.get(url).content.decode('latin-1').split('\\n')\n",
    "    idx = 0\n",
    "    while idx < len(word_list):\n",
    "        if \";\" in word_list[idx] or word_list[idx] == \"\":\n",
    "            word_list.pop(idx)\n",
    "        else:\n",
    "            idx += 1\n",
    "    return word_list\n",
    "# p_url = 'http://ptrckprry.com/course/ssd/data/positive-words.txt'\n",
    "# n_url = 'http://ptrckprry.com/course/ssd/data/negative-words.txt'\n",
    "# pos_word_list = get_words(p_url)\n",
    "# neg_word_list = get_words(n_url)\n",
    "# pos_word_df = pd.DataFrame(pos_word_list)\n",
    "# neg_word_df = pd.DataFrame(neg_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689f25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word_df = pd.read_csv('pos_word_list.csv',header=None, index_col=None)\n",
    "neg_word_df = pd.read_csv('neg_word_list.csv',header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43fb0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg_sentiment(s):\n",
    "#     p_url = 'http://ptrckprry.com/course/ssd/data/positive-words.txt'\n",
    "#     n_url = 'http://ptrckprry.com/course/ssd/data/negative-words.txt'\n",
    "#     pos_word_list = get_words(p_url)\n",
    "#     neg_word_list = get_words(n_url)\n",
    "#     pos_word_df = pd.DataFrame(pos_word_list)\n",
    "#     neg_word_df = pd.DataFrame(neg_word_list)\n",
    "    pos_word_df = pd.read_csv('pos_word_list.csv',header=None, index_col=None)\n",
    "    neg_word_df = pd.read_csv('neg_word_list.csv',header=None, index_col=None)\n",
    "    \n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    words = word_tokenize(s)\n",
    "    words = remove_stop_word(words)\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        if w in pos_word_df:\n",
    "            pos_count += 1\n",
    "        if w in neg_word_df:\n",
    "            neg_count += 1\n",
    "    pos_pct = pos_count/len(words)\n",
    "    neg_pct = neg_count/len(words)\n",
    "    pos_neg_diff = pos_pct - neg_pct\n",
    "    ret_d = {'pos rate': pos_pct,\n",
    "            'neg rate': neg_pct,\n",
    "            'pos neg diff': pos_neg_diff}\n",
    "    return ret_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80452f",
   "metadata": {},
   "source": [
    "# NRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0f39243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrc_emotion_dict():\n",
    "    file_dir = \"./data/NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n",
    "    with open(file_dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    emotion_dict = dict()\n",
    "    start_idx = 46\n",
    "    for i in range(start_idx, len(lines)):\n",
    "        line_l = lines[i].strip().split()\n",
    "        word = line_l[0]\n",
    "        emotion = line_l[1]\n",
    "        t_or_f = line_l[2]\n",
    "        if t_or_f == \"1\":\n",
    "            if word in emotion_dict.keys():\n",
    "                emotion_dict[word].append(emotion)\n",
    "            else:\n",
    "                emotion_dict[word] = [emotion]\n",
    "    return emotion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a44b71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrc_sentiment(s):\n",
    "    count_dict = {\"anger\": 0,\n",
    "                \"anticipation\": 0,\n",
    "                \"disgust\": 0,\n",
    "                \"fear\": 0,\n",
    "                \"joy\": 0,\n",
    "                \"negative\": 0,\n",
    "                \"positive\": 0,\n",
    "                \"sadness\": 0,\n",
    "                \"surprise\": 0,\n",
    "                \"trust\": 0}\n",
    "    emotion_dict = nrc_emotion_dict()\n",
    "    words = word_tokenize(s)\n",
    "    words = remove_stop_word(words)\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        if w in emotion_dict.keys():\n",
    "            e_l = emotion_dict[w]\n",
    "            for j in range(len(e_l)):\n",
    "                e = e_l[j]\n",
    "                count_dict[e] += 1\n",
    "    for k in count_dict.keys():\n",
    "        count_dict[k] /= len(words)\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec8279",
   "metadata": {},
   "source": [
    "# Final - Combine Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff1b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5854fff3",
   "metadata": {},
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69ee9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_df(filename):\n",
    "    twt_df = pd.read_excel(filename)\n",
    "    twt_df = twt_df.drop(['Unnamed: 0', 'place', 'language', 'created_at'], axis = 1)\n",
    "    twt_df['date'] = twt_df['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    twt_df['hour'] = twt_df['time'].apply(lambda x: datetime.datetime.strptime(x, '%H:%M:%S').hour)\n",
    "    twt_df = twt_df.drop(['time'], axis = 1)\n",
    "    twt_df = twt_df.sort_values(['date','hour']).reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "    dt_df = pd.DataFrame(data = None, \n",
    "                     index=twt_df.groupby(['date']).count().index, \n",
    "                     columns=['tweets', 'num', 'at_count', 'tag_count', 'reply_sum', 'retweet_sum', 'like_sum'])\n",
    "\n",
    "    for i in range(len(twt_df)):\n",
    "    # for i in range(2500):\n",
    "        dt = twt_df.iloc[i]['date']\n",
    "        hour = twt_df.iloc[i]['hour']\n",
    "        tweet = twt_df.iloc[i]['tweet']\n",
    "        reply = twt_df.iloc[i]['replies_count']\n",
    "        retweet = twt_df.iloc[i]['retweets_count']\n",
    "        like = twt_df.iloc[i]['likes_count']\n",
    "\n",
    "        tweet_d = remove_at(tweet)\n",
    "        tweet = tweet_d['return_string']\n",
    "        at_count = tweet_d['count']\n",
    "\n",
    "        tweet_d = get_hashtag(tweet)\n",
    "        tweet = tweet_d['return_string']\n",
    "        tag_count = tweet_d['tag_count']\n",
    "\n",
    "        tweet = remove_hyperlink(tweet)\n",
    "\n",
    "        if pd.isna(dt_df.loc[dt]['tweets']):\n",
    "            dt_df.loc[dt]['tweets'] = str(tweet)\n",
    "            dt_df.loc[dt]['num'] = 1\n",
    "            dt_df.loc[dt]['reply_sum'] = reply\n",
    "            dt_df.loc[dt]['retweet_sum'] = retweet\n",
    "            dt_df.loc[dt]['like_sum'] = like\n",
    "            dt_df.loc[dt]['at_count'] = at_count \n",
    "            dt_df.loc[dt]['tag_count'] = tag_count \n",
    "\n",
    "        else:\n",
    "            dt_df.loc[dt]['tweets'] += ' ' + str(tweet)\n",
    "            dt_df.loc[dt]['num'] += 1\n",
    "            dt_df.loc[dt]['reply_sum'] += reply\n",
    "            dt_df.loc[dt]['retweet_sum'] += retweet\n",
    "            dt_df.loc[dt]['like_sum'] += like\n",
    "            dt_df.loc[dt]['at_count'] += at_count \n",
    "            dt_df.loc[dt]['tag_count'] += tag_count \n",
    "\n",
    "    dt_df['tweets'] = dt_df['tweets'].apply(lambda x: emoji_process(x))\n",
    "    return dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b9296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df20e683",
   "metadata": {},
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a38f736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_df(dt_df):\n",
    "    col_names = ['date', 'tweets', 'pos', 'neg', 'pos - neg',\n",
    "                                         'nrc anger', 'nrc anticipation', 'nrc disgust', 'nrc fear', 'nrc joy', \n",
    "                                         'nrc neg', 'nrc pos', 'nrc sadness', 'nrc surprise', 'nrc trust']\n",
    "    col_names.extend(dt_df.columns.to_list()[1:])\n",
    "    sentiment_df = pd.DataFrame(data = None,\n",
    "                               index = range(len(dt_df)),\n",
    "                               columns = col_names)\n",
    "    for i in range(len(dt_df)):\n",
    "        dt = dt_df.index[i]\n",
    "        s = dt_df.iloc[i]['tweets']\n",
    "\n",
    "        tweet = dt_df.iloc[i]['tweets']\n",
    "        num = dt_df.iloc[i]['num']\n",
    "        at_count = dt_df.iloc[i]['at_count']\n",
    "        tag_count = dt_df.iloc[i]['tag_count']\n",
    "        reply = dt_df.iloc[i]['reply_sum']\n",
    "        retweet = dt_df.iloc[i]['retweet_sum']\n",
    "        like = dt_df.iloc[i]['like_sum']\n",
    "\n",
    "        sentiment_df.iloc[i]['date'] = dt\n",
    "        sentiment_df.iloc[i]['tweets'] = tweet\n",
    "        sentiment_df.iloc[i]['num'] = num\n",
    "        sentiment_df.iloc[i]['at_count'] = at_count\n",
    "        sentiment_df.iloc[i]['tag_count'] = tag_count\n",
    "        sentiment_df.iloc[i]['reply_sum'] = reply\n",
    "        sentiment_df.iloc[i]['retweet_sum'] = retweet\n",
    "        sentiment_df.iloc[i]['like_sum'] = like\n",
    "\n",
    "\n",
    "        pos_neg_d = pos_neg_sentiment(s)\n",
    "        nrc_d = nrc_sentiment(s)\n",
    "        sentiment_df.iloc[i][['pos','neg','pos - neg']] = list(pos_neg_d.values())\n",
    "        sentiment_df.iloc[i][['nrc anger', 'nrc anticipation', 'nrc disgust', 'nrc fear', 'nrc joy', \n",
    "                    'nrc neg', 'nrc pos', 'nrc sadness', 'nrc surprise', 'nrc trust']] = list(nrc_d.values())\n",
    "        \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa42ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee9ff607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_process(filename):\n",
    "    \n",
    "    dt_df = get_dt_df(filename)\n",
    "    sentiment_df = get_sentiment_df(dt_df)\n",
    "    \n",
    "    NAME_MATCH = {'aa': 'AAL',\n",
    "                 'dis': 'DIS',\n",
    "                 'pep': 'PEP'}\n",
    "    temp_filename = filename.split('\\\\')[-1].split('.')[0][:-4]\n",
    "    y = filename.split('\\\\')[-1].split('.')[0][-4:]\n",
    "    output_name = NAME_MATCH[temp_filename]\n",
    "    output_dir = 'twitter\\\\' + output_name + f'_{y}_twt.csv'\n",
    "    \n",
    "    sentiment_df.to_csv(output_dir, \n",
    "                       header=True,\n",
    "                       index=False,\n",
    "                       encoding='utf-8-sig')\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b2c0c",
   "metadata": {},
   "source": [
    "# File Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3186e",
   "metadata": {},
   "source": [
    "2018-2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cea8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_l = list(range(2018,2022))\n",
    "# prefix = 'twitter\\DIS_PEP_AAL_'\n",
    "# ticker_l = ['aa', 'disney', 'pepsi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a145ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_l = []\n",
    "# for i in range(len(year_l)):\n",
    "#     y = year_l[i]\n",
    "#     temp_prefix = prefix + str(y) + '\\\\'\n",
    "#     for j in range(len(ticker_l)):\n",
    "#         t = ticker_l[j]\n",
    "#         temp_filename = temp_prefix + t + str(y) + '.xlsx'\n",
    "#         filename_l.append(temp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4755990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_l = [2017]\n",
    "prefix = 'twitter\\DIS_PEP_AAL_'\n",
    "ticker_l = ['aa', 'dis', 'pep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6e5e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_l = []\n",
    "for i in range(len(year_l)):\n",
    "    y = year_l[i]\n",
    "    temp_prefix = prefix + str(y) + '\\\\'\n",
    "    for j in range(len(ticker_l)):\n",
    "        t = ticker_l[j]\n",
    "        temp_filename = temp_prefix + t + str(y) + '.xlsx'\n",
    "        filename_l.append(temp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0eec73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cef33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc3ad82",
   "metadata": {},
   "source": [
    "# Run for All Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4258548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---There are 3 files in total--- \n",
      "---Processing file No. 1---\n",
      "---Processing file No. 2---\n"
     ]
    }
   ],
   "source": [
    "sentiment_l = []\n",
    "print(f'---There are {len(filename_l)} files in total--- ')\n",
    "for i in range(1,len(filename_l)):\n",
    "    print(f'---Processing file No. {i}---')\n",
    "    filename = filename_l[i]\n",
    "    twitter_process(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad1376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6320d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64dcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022fea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b45a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"twitter\\DIS_PEP_AAL_2021\\pepsi2021.xlsx\"\n",
    "# dt_df = get_dt_df(filename)\n",
    "# sentiment_df = get_sentiment_df(dt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0962f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"twitter\\DIS_PEP_AAL_2021\\pepsi2021.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97203de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f244974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c5a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad4ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8b555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cda142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentiment(filename):\n",
    "#     news = pd.read_csv(filename,\n",
    "#                   header = 0,\n",
    "#                   index_col = None)\n",
    "#     sentiment_df = pd.DataFrame(data = None,\n",
    "#                                index = range(len(news)),\n",
    "#                                columns = ['date', 'news', 'pos', 'neg', 'pos - neg',\n",
    "#                                          'nrc anger', 'nrc anticipation', 'nrc disgust', 'nrc fear', 'nrc joy', \n",
    "#                                          'nrc neg', 'nrc pos', 'nrc sadness', 'nrc surprise', 'nrc trust'])\n",
    "#     for i in range(len(news)):\n",
    "#         dt = news.iloc[i][0]\n",
    "#         s = news.iloc[i][1]\n",
    "#         if pd.isna(s):\n",
    "#             sentiment_df.iloc[i]['date'] = dt\n",
    "#         else:\n",
    "#             pos_neg_d = pos_neg_sentiment(s)\n",
    "#             nrc_d = nrc_sentiment(s)\n",
    "#             sentiment_df.iloc[i]['date'] = dt\n",
    "#             sentiment_df.iloc[i]['news'] = s\n",
    "#             sentiment_df.iloc[i][['pos','neg','pos - neg']] = list(pos_neg_d.values())\n",
    "#             sentiment_df.iloc[i][['nrc anger', 'nrc anticipation', 'nrc disgust', 'nrc fear', 'nrc joy', \n",
    "#                         'nrc neg', 'nrc pos', 'nrc sadness', 'nrc surprise', 'nrc trust']] = list(nrc_d.values())\n",
    "    \n",
    "#     sentiment_df.to_csv(filename[:3] + '_news_sentiment.csv', \n",
    "#                        header=True, \n",
    "#                        index=True)\n",
    "#     return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0291409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752a1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b853c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'aal_dt_news.csv'\n",
    "# get_sentiment(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a62228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98442e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63223f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463c453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a1647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57aa86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4779ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1aa15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f23a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf38ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e01ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd5073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70df93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_dt_df.to_csv('aal_dt_news.csv',\n",
    "#                  header=True,\n",
    "#                  index=False,\n",
    "#                  encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
